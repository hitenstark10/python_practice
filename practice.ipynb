{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5074c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d557a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response : content='Hey\\u202fMoe! ðŸ‘‹ Letâ€™s break down the difference between **â€œAgenticâ€** (or *agentic behavior*) and an **AI\\u202fAgent**. Both concepts involve â€œagents,â€ but they live in different worlds and serve different purposes. Hereâ€™s a quick, friendly guide you can use to get the gist.\\n\\n---\\n\\n## 1. What Does â€œAgenticâ€ Mean?\\n\\n**Agentic** comes from the word *agent* and is used mainly in psychology, philosophy, and social science. It describes the capacity of a being (usually a human, but sometimes an animal or even a robot) to act intentionally, make choices, and influence the world.\\n\\n| Feature | What it looks like |\\n|---------|--------------------|\\n| **Intentionality** | Acting with a purpose (â€œIâ€™m going to finish this report because I want a promotionâ€). |\\n| **Selfâ€‘directed control** | Deciding for yourself, not just reacting to external commands. |\\n| **Responsibility & accountability** | You can be praised or blamed for what you do. |\\n| **Sense of agency** | The feeling â€œI did that!â€ (often studied in neuroscience). |\\n| **Freeâ€‘will / autonomy** | At least in everyday language, we treat people as having the freedom to choose. |\\n\\n**Examples of agentic behavior**  \\n- Choosing a career path.  \\n- Deciding to help a stranger.  \\n- Planning a vacation and booking the tickets yourself.  \\n\\nIn short, *agentic* is a **human (or animal) trait** that emphasizes **volition, selfâ€‘direction, and responsibility**.\\n\\n---\\n\\n## 2. What Is an â€œAI Agentâ€?\\n\\nAn **AI Agent** is a software entity built to **perceive its environment, reason, and take actions** in order to achieve a goal. It can be as simple as a thermostat that turns the heat on when itâ€™s cold, or as sophisticated as a virtual personal assistant that schedules meetings, writes code, or pilots a selfâ€‘driving car.\\n\\n### Core ingredients of an AI Agent\\n\\n| Component | Description |\\n|-----------|-------------|\\n| **Perception** | Sensors or data inputs (e.g., camera, microphone, API data). |\\n| **Policy / Model** | The algorithm that decides what to do next (rules, machineâ€‘learning model, reinforcementâ€‘learning policy). |\\n| **Actuation** | The output actions (sending a command, generating text, moving a robot arm). |\\n| **Goal / Reward** | A defined objective (minimize energy use, maximize user satisfaction, complete a task). |\\n| **Learning (optional)** | Ability to improve over time from experience. |\\n\\n**Examples of AI Agents**  \\n- **ChatGPT** â€“ receives text, processes it with a language model, and replies.  \\n- **Siri / Alexa** â€“ listen to voice commands, query services, and act (play music, set reminders).  \\n- **Autonomous drones** â€“ perceive surroundings via cameras, plan routes, and navigate.  \\n- **Game bots** â€“ observe the game state and decide moves to win.\\n\\n---\\n\\n## 3. Key Differences at a Glance\\n\\n| Dimension | Agentic (Human/Animal) | AI Agent (Software) |\\n|-----------|------------------------|----------------------|\\n| **Source of Intent** | Internal desires, values, emotions, free will. | Preâ€‘programmed goals or learned reward functions. |\\n| **Consciousness** | Usually (subjectively) aware, experiences feelings. | No subjective experience (unless we someday create conscious AI). |\\n| **Responsibility** | Humans can be held morally/legal accountable. | Responsibility typically lies with designers, operators, or owners. |\\n| **Learning Mechanism** | Biological learning, socialization, reflection. | Machineâ€‘learning algorithms, reinforcement learning, supervised updates. |\\n| **Flexibility** | Highly adaptable, can create new goals on the fly. | Bounded by its programming and training data; can be flexible if designed for openâ€‘ended learning. |\\n| **Transparency** | We can introspect (â€œI feel X, so I do Yâ€). | Often a â€œblack boxâ€ (especially deepâ€‘learning models). |\\n| **Physical embodiment** | Bodies with senses and motor capabilities. | May be purely virtual (chatbot) or embodied (robot). |\\n\\n---\\n\\n## 4. Why the Confusion Happens\\n\\n- **Language overlap:** Both use the word *agent*, so people sometimes conflate â€œagentic behaviorâ€ (a human trait) with â€œAI agentsâ€ (software).\\n- **Anthropomorphism:** We naturally describe AI agents as if they have intentions (â€œthe bot wants to help youâ€). Thatâ€™s a useful metaphor, but technically the â€œdesireâ€ is just a programmed objective.\\n- **Emergent capabilities:** Modern AI agents (especially large language models) can *appear* agenticâ€”they can plan, reason, and adaptâ€”so the line gets blurrier. Still, the underlying mechanism is a set of statistical patterns, not genuine volition.\\n\\n---\\n\\n## 5. A Simple Analogy\\n\\n> **Imagine a chess player vs. a chessâ€‘playing robot.**  \\n> \\n> - The human player decides to take a risk because they *feel* confident (agentic).  \\n> - The robot follows a search algorithm that maximizes its evaluation function (AI agent).  \\n> \\n> Both move pieces, but the source of the decision differs: internal desire vs. programmed objective.\\n\\n---\\n\\n## 6. Bottom Line for Moe\\n\\n- **Agentic** = *You* (or any sentient creature) acting with intention, free will, and responsibility.  \\n- **AI Agent** = A *software system* that perceives, decides, and acts **according to a goal set by its creators**. It may *behave* like an agent, but it doesnâ€™t have its own desires or consciousness.\\n\\nUnderstanding the distinction helps when we talk about ethics, accountability, and design. We hold humans accountable for agentic actions, while we hold the designers/owners of AI agents accountable for the outcomes those agents produce.\\n\\nHope that clears things up! If you want to dive deeper into any of the concepts (e.g., reinforcement learning, moral agency, or specific AI agent examples), just let me know. ðŸš€' additional_kwargs={'reasoning_content': 'The user: \"tell moe about Agentic vs AI Agent\". Likely they want an explanation of the difference between \"Agentic\" (maybe agentic AI? Or agentic behavior) vs \"AI Agent\". Maybe they have a person named Moe, they want to explain. So produce a clear, accessible explanation, maybe with examples, differences. Should be friendly. No disallowed content. So answer.'} response_metadata={'token_usage': {'completion_tokens': 1387, 'prompt_tokens': 79, 'total_tokens': 1466, 'completion_time': 2.9941839789999998, 'completion_tokens_details': {'reasoning_tokens': 83}, 'prompt_time': 0.003034507, 'prompt_tokens_details': None, 'queue_time': 0.049110833, 'total_time': 2.997218486}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8a618bed98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b7f13-7b3c-7660-b281-29a9e34f00d7-0' usage_metadata={'input_tokens': 79, 'output_tokens': 1387, 'total_tokens': 1466, 'output_token_details': {'reasoning': 83}}\n"
     ]
    }
   ],
   "source": [
    "model = ChatGroq(model = \"openai/gpt-oss-120b\")\n",
    "res = model.invoke(\"tell moe about Agentic vs AI Agent\")\n",
    "print(f\"Response : {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34f9134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Heyâ€¯Moe! ðŸ‘‹ Letâ€™s break down the difference between **â€œAgenticâ€** (or *agentic behavior*) and an **AIâ€¯Agent**. Both concepts involve â€œagents,â€ but they live in different worlds and serve different purposes. Hereâ€™s a quick, friendly guide you can use to get the gist.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. What Does â€œAgenticâ€ Mean?\n",
      "\n",
      "**Agentic** comes from the word *agent* and is used mainly in psychology, philosophy, and social science. It describes the capacity of a being (usually a human, but sometimes an animal or even a robot) to act intentionally, make choices, and influence the world.\n",
      "\n",
      "| Feature | What it looks like |\n",
      "|---------|--------------------|\n",
      "| **Intentionality** | Acting with a purpose (â€œIâ€™m going to finish this report because I want a promotionâ€). |\n",
      "| **Selfâ€‘directed control** | Deciding for yourself, not just reacting to external commands. |\n",
      "| **Responsibility & accountability** | You can be praised or blamed for what you do. |\n",
      "| **Sense of agency** | The feeling â€œI did that!â€ (often studied in neuroscience). |\n",
      "| **Freeâ€‘will / autonomy** | At least in everyday language, we treat people as having the freedom to choose. |\n",
      "\n",
      "**Examples of agentic behavior**  \n",
      "- Choosing a career path.  \n",
      "- Deciding to help a stranger.  \n",
      "- Planning a vacation and booking the tickets yourself.  \n",
      "\n",
      "In short, *agentic* is a **human (or animal) trait** that emphasizes **volition, selfâ€‘direction, and responsibility**.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. What Is an â€œAI Agentâ€?\n",
      "\n",
      "An **AI Agent** is a software entity built to **perceive its environment, reason, and take actions** in order to achieve a goal. It can be as simple as a thermostat that turns the heat on when itâ€™s cold, or as sophisticated as a virtual personal assistant that schedules meetings, writes code, or pilots a selfâ€‘driving car.\n",
      "\n",
      "### Core ingredients of an AI Agent\n",
      "\n",
      "| Component | Description |\n",
      "|-----------|-------------|\n",
      "| **Perception** | Sensors or data inputs (e.g., camera, microphone, API data). |\n",
      "| **Policy / Model** | The algorithm that decides what to do next (rules, machineâ€‘learning model, reinforcementâ€‘learning policy). |\n",
      "| **Actuation** | The output actions (sending a command, generating text, moving a robot arm). |\n",
      "| **Goal / Reward** | A defined objective (minimize energy use, maximize user satisfaction, complete a task). |\n",
      "| **Learning (optional)** | Ability to improve over time from experience. |\n",
      "\n",
      "**Examples of AI Agents**  \n",
      "- **ChatGPT** â€“ receives text, processes it with a language model, and replies.  \n",
      "- **Siri / Alexa** â€“ listen to voice commands, query services, and act (play music, set reminders).  \n",
      "- **Autonomous drones** â€“ perceive surroundings via cameras, plan routes, and navigate.  \n",
      "- **Game bots** â€“ observe the game state and decide moves to win.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Key Differences at a Glance\n",
      "\n",
      "| Dimension | Agentic (Human/Animal) | AI Agent (Software) |\n",
      "|-----------|------------------------|----------------------|\n",
      "| **Source of Intent** | Internal desires, values, emotions, free will. | Preâ€‘programmed goals or learned reward functions. |\n",
      "| **Consciousness** | Usually (subjectively) aware, experiences feelings. | No subjective experience (unless we someday create conscious AI). |\n",
      "| **Responsibility** | Humans can be held morally/legal accountable. | Responsibility typically lies with designers, operators, or owners. |\n",
      "| **Learning Mechanism** | Biological learning, socialization, reflection. | Machineâ€‘learning algorithms, reinforcement learning, supervised updates. |\n",
      "| **Flexibility** | Highly adaptable, can create new goals on the fly. | Bounded by its programming and training data; can be flexible if designed for openâ€‘ended learning. |\n",
      "| **Transparency** | We can introspect (â€œI feel X, so I do Yâ€). | Often a â€œblack boxâ€ (especially deepâ€‘learning models). |\n",
      "| **Physical embodiment** | Bodies with senses and motor capabilities. | May be purely virtual (chatbot) or embodied (robot). |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Why the Confusion Happens\n",
      "\n",
      "- **Language overlap:** Both use the word *agent*, so people sometimes conflate â€œagentic behaviorâ€ (a human trait) with â€œAI agentsâ€ (software).\n",
      "- **Anthropomorphism:** We naturally describe AI agents as if they have intentions (â€œthe bot wants to help youâ€). Thatâ€™s a useful metaphor, but technically the â€œdesireâ€ is just a programmed objective.\n",
      "- **Emergent capabilities:** Modern AI agents (especially large language models) can *appear* agenticâ€”they can plan, reason, and adaptâ€”so the line gets blurrier. Still, the underlying mechanism is a set of statistical patterns, not genuine volition.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. A Simple Analogy\n",
      "\n",
      "> **Imagine a chess player vs. a chessâ€‘playing robot.**  \n",
      "> \n",
      "> - The human player decides to take a risk because they *feel* confident (agentic).  \n",
      "> - The robot follows a search algorithm that maximizes its evaluation function (AI agent).  \n",
      "> \n",
      "> Both move pieces, but the source of the decision differs: internal desire vs. programmed objective.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Bottom Line for Moe\n",
      "\n",
      "- **Agentic** = *You* (or any sentient creature) acting with intention, free will, and responsibility.  \n",
      "- **AI Agent** = A *software system* that perceives, decides, and acts **according to a goal set by its creators**. It may *behave* like an agent, but it doesnâ€™t have its own desires or consciousness.\n",
      "\n",
      "Understanding the distinction helps when we talk about ethics, accountability, and design. We hold humans accountable for agentic actions, while we hold the designers/owners of AI agents accountable for the outcomes those agents produce.\n",
      "\n",
      "Hope that clears things up! If you want to dive deeper into any of the concepts (e.g., reinforcement learning, moral agency, or specific AI agent examples), just let me know. ðŸš€\n"
     ]
    }
   ],
   "source": [
    "res.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e5c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
